{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributing a model to the Kipoi model repository\n",
    "\n",
    "This notebook will show you how to contribute a model to the [Kipoi model repository](https://github.com/kipoi/models). \n",
    "\n",
    "## Kipoi basics\n",
    "\n",
    "Contributing a model to Kipoi means writing a sub-folder with all the required files to the [Kipoi model repository](https://github.com/kipoi/models) via pull request.\n",
    "\n",
    "Two main components of the model repository are **model** and **dataloader**.\n",
    "\n",
    "#### Model\n",
    "\n",
    "Model takes as input numpy arrays and outputs numpy arrays. In practice, a model needs to implement the `predict_on_batch(x)` method, where `x` is dictionary/list of numpy arrays. The model contributor needs to provide one of the following:\n",
    "\n",
    "- Serialized Keras model\n",
    "- Serialized Sklearn model\n",
    "- Custom model inheriting from `keras.model.BaseModel`.\n",
    "  - all the required files, i.e. weights need to be loaded in the `__init__`\n",
    "\n",
    "#### Dataloader\n",
    "\n",
    "Dataloader takes raw file paths or other parameters as argument and outputs modelling-ready numpy arrays. The dataloading can be done through a generator---batch-by-batch, sample-by-sample---or by just returning the whole dataset. The goal is to work really with raw files (say fasta, bed, vcf, etc in bioinformatics), as this allows to make model predictions on new datasets without going through the burden of running custom pre-processing scripts.\n",
    "\n",
    "### Folder layout\n",
    "\n",
    "Here is an example folder structure of a Kipoi model:\n",
    "\n",
    "```\n",
    "├── dataloader.py     # implements the dataloader\n",
    "├── dataloader.yaml   # describes the dataloader\n",
    "├── dataloader_files/      #/ files required by the dataloader\n",
    "│   ├── x_transfomer.pkl\n",
    "│   └── y_transfomer.pkl\n",
    "├── model.yaml        # describes the model\n",
    "├── model_files/           #/ files required by the model\n",
    "│   ├── model.json\n",
    "│   └── weights.h5\n",
    "└── test_files/            #/ small test files\n",
    "    ├── features.csv\n",
    "    ├── targets.csv\n",
    "    └── test.json\n",
    "```    \n",
    "\n",
    "Two most important files are `model.yaml` and `dataloader.yaml`. They provide a complete description about the model, the dataloader and the files they depend on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing a simple Iris-classifier\n",
    "\n",
    "Details about the individual files will be revealed throught the tutorial bellow. A simple Keras model will be trained to predict the Iris plant class from the well-known [Iris](archive.ics.uci.edu/ml/datasets/Iris) dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "1. Train the model\n",
    "2. Generate `dataloader_files/`\n",
    "3. Generate `model_files/`\n",
    "4. Generate `test_files/`\n",
    "5. Write `model.yaml`\n",
    "6. Write `dataloader.yaml`\n",
    "7. Write `dataloader.py`\n",
    "8. Test with the model with `$ kipoi test .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view more info about the dataset\n",
    "# print(iris[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "y_transformer = LabelBinarizer().fit(iris[\"target\"])\n",
    "x_transformer = StandardScaler().fit(iris[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_transformer.transform(iris[\"data\"])\n",
    "y = y_transformer.transform(iris[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9007,  1.0321, -1.3413, -1.313 ],\n",
       "       [-1.143 , -0.125 , -1.3413, -1.313 ],\n",
       "       [-1.3854,  0.3378, -1.3981, -1.313 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train an example model\n",
    "\n",
    "Let's train a simple linear-regression model using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5c6a6b7a20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import keras.layers as kl\n",
    "\n",
    "model = Sequential([kl.Dense(units=3, input_shape=(4, ))])\n",
    "model.compile(\"adam\", \"categorical_crossentropy\")\n",
    "\n",
    "model.fit(x, y, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate `dataloader_files/`\n",
    "\n",
    "Now that we have everything we need, let's start writing the files to model's directory (here `model_template/`). \n",
    "\n",
    "In reality, you would need to \n",
    "1. Fork the [kipoi/models repository](https://github.com/kipoi/models)\n",
    "2. Clone your repository fork, ignoring all the git-lfs files\n",
    "    - `$ git lfs clone git@github.com:<your_username>/models.git '-I /'`\n",
    "3. Create a new folder `<mynewmodel>` containing all the model files in the repostiory root\n",
    "    - put all the non-code files (serialized models, test data) into a `*files/` directory, where `*` can be anything. These will namely be tracked by `git-lfs` instead of `git`.\n",
    "      - Examples: `model_files/`, `dataloader_files/`\n",
    "4. Test your repository locally:\n",
    "    - `$ kipoi test <mynewmodel_folder>`\n",
    "5. Commit, push to your forked remote and submit a pull request to [github.com/kipoi/models](https://github.com/kipoi/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader can use some trained transformer (here the `LabelBinarizer` and `StandardScaler` transformers form sklearn). These should be written to `dataloader_files/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../examples/iris_model_template'\n",
      "/data/nasif12/home_if12/avsec/projects-work/kipoi/examples/iris_model_template\n"
     ]
    }
   ],
   "source": [
    "cd ../examples/iris_model_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"dataloader_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataloader_files/y_transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_transformer, f)\n",
    "\n",
    "with open(\"dataloader_files/x_transformer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(x_transformer, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_transformer.pkl  y_transformer.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls dataloader_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate `model_files/`\n",
    "\n",
    "The serialized model weights and architecture go to `model_files/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"model_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture\n",
    "with open(\"model_files/model.json\", \"w\") as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "model.save_weights(\"model_files/weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate `test_files/`\n",
    "\n",
    "`test_files/` should contain a small subset of the raw files the dataloader will read.\n",
    "\n",
    "#### Numpy arrays -> pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'DESCR', 'target', 'target_names', 'feature_names'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris[\"data\"][:20], columns=iris[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame({\"class\": iris[\"target\"][:20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"test_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"test_files/features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv(\"test_files/targets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\r\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 test_files/targets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm),sepal width (cm),petal length (cm),petal width (cm)\r\n",
      "5.1,3.5,1.4,0.2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 test_files/features.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write `model.yaml`\n",
    "\n",
    "The `model.yaml` for this model should look like this:\n",
    "\n",
    "```yaml\n",
    "type: keras  # use `kipoi.model.KerasModel`\n",
    "args:  # arguments of `kipoi.model.KerasModel`\n",
    "    arch: model_files/model.json\n",
    "    weights: model_files/weights.h5\n",
    "default_dataloader: . # path to the dataloader directory. Here it's defined in the same directory\n",
    "info: # General information about the model\n",
    "    author: Your Name\n",
    "    name: NameOfThisModel\n",
    "    version: 0.1\n",
    "    descr: Model predicting the Iris species\n",
    "dependencies:\n",
    "    conda: # install via conda\n",
    "      - python=3.5\n",
    "      - h5py\n",
    "      # - soumith::pytorch  # specify packages from other channels via <channel>::<package>      \n",
    "    pip:   # install via pip\n",
    "      - keras>=2.0.4\n",
    "      - tensorflow>=1.0\n",
    "schema:  # Model schema\n",
    "    inputs:\n",
    "        features:\n",
    "            shape: (4,)  # array shape of a single sample (omitting the batch dimension)\n",
    "            descr: \"Features in cm: sepal length, sepal width, petal length, petal width.\"\n",
    "    targets:\n",
    "        plant_class:\n",
    "            shape: (3,)\n",
    "            descr: \"One-hot encoded array of classes: setosa, versicolor, virginica.\"\n",
    "```\n",
    "\n",
    "All file paths are relative relative to `model.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write `dataloader.yaml`\n",
    "\n",
    "```yaml\n",
    "type: Dataset\n",
    "defined_as: dataloader.py::MyDataset  # We need to implement MyDataset class inheriting from kipoi.data.Dataset in dataloader.py\n",
    "args:\n",
    "    features_file:\n",
    "        # descr: > allows multi-line fields\n",
    "        descr: >\n",
    "          Csv file of the Iris Plants Database from\n",
    "          http://archive.ics.uci.edu/ml/datasets/Iris features.\n",
    "        type: str\n",
    "    targets_file:\n",
    "        descr: >\n",
    "          Csv file of the Iris Plants Database targets.\n",
    "          Not required for making the prediction.\n",
    "        type: str\n",
    "        optional: True  # if not present, the `targets` field will not be present in the dataloader output\n",
    "info:\n",
    "    author: Your Name\n",
    "    name: NameOfThisModel\n",
    "    version: 0.1\n",
    "    descr: Model predicting the Iris species\n",
    "dependencies:\n",
    "    conda:\n",
    "      - python=3.5\n",
    "      - pandas\n",
    "      - numpy\n",
    "      - sklearn\n",
    "output_schema:\n",
    "    inputs:\n",
    "        features:\n",
    "            shape: (4,)\n",
    "            descr: Features in cm: sepal length, sepal width, petal length, petal width.\n",
    "    targets:\n",
    "        plant_class:\n",
    "            shape: (3, )\n",
    "            descr: One-hot encoded array of classes: setosa, versicolor, virginica.\n",
    "    metadata:  # field providing additional information to the samples (not directly required by the model)\n",
    "        example_row_number:\n",
    "            shape: (1,)\n",
    "            descr: Just an example metadata column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write `dataloader.py`\n",
    "\n",
    "Finally, let's implement MyDataset. We need to implement two methods: `__len__` and `__getitem__`. \n",
    "\n",
    "`__getitem__` will return one item of the dataset. In our case, this is a dictionary with `output_schema` described in `dataloader.yaml`.\n",
    "\n",
    "For more information about writing such dataloaders, see the [Data Loading and Processing Tutorial from pytorch](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoi.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_pickle(f):\n",
    "    with open(f, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features_file, targets_file=None):\n",
    "        self.features_file = features_file\n",
    "        self.targets_file = targets_file\n",
    "        \n",
    "        self.y_transformer = read_pickle(\"dataloader_files/y_transformer.pkl\")\n",
    "        self.x_transformer = read_pickle(\"dataloader_files/x_transformer.pkl\")\n",
    "\n",
    "        self.features = pd.read_csv(features_file)\n",
    "        if targets_file is not None:\n",
    "            self.targets = pd.read_csv(targets_file)\n",
    "            assert len(self.targets) == len(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_features = np.ravel(self.x_transformer.transform(self.features.iloc[idx].values[np.newaxis]))\n",
    "        if self.targets_file is None:\n",
    "            y_class = {}\n",
    "        else:\n",
    "            y_class = np.ravel(self.y_transformer.transform(self.targets.iloc[idx].values[np.newaxis]))\n",
    "        return {\n",
    "            \"inputs\": {\n",
    "                \"features\": x_features\n",
    "            },\n",
    "            \"targets\": {\n",
    "                \"plant_class\": y_class\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"example_row_number\": np.array([idx])\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MyDataset(\"test_files/features.csv\", \"test_files/targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'features': array([-0.5372,  1.9577, -1.1707, -1.05  ])},\n",
       " 'metadata': {'example_row_number': array([5])},\n",
       " 'targets': {'plant_class': array([1, 0, 0])}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call __getitem__\n",
    "ds[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since MyDatset inherits from `kipoi.data.Dataset`, it has some additional nice feature. See [python-sdk.ipynb](python-sdk.ipynb) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'features': array([[-0.9007,  1.0321, -1.3413, -1.313 ],\n",
       "         [-1.143 , -0.125 , -1.3413, -1.313 ],\n",
       "         [-1.3854,  0.3378, -1.3981, -1.313 ]])},\n",
       " 'metadata': {'example_row_number': array([[0],\n",
       "         [1],\n",
       "         [2]])},\n",
       " 'targets': {'plant_class': array([[1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0]])}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch-iterator\n",
    "it = ds.batch_iter(batch_size=3, shuffle=False, num_workers=2)\n",
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.load_all()  # load the whole dataset into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test with the model with `$ kipoi test .`\n",
    "\n",
    "Before we contribute the model to the repository, let's run the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/bin/kipoi\", line 11, in <module>\r\n",
      "    load_entry_point('kipoi==0.0.1', 'console_scripts', 'kipoi')()\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/__main__.py\", line 56, in main\r\n",
      "    command_fn(args.command, sys.argv[2:])\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/pipeline.py\", line 147, in cli_test\r\n",
      "    mh = kipoi.get_model(args.model, args.source)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/model.py\", line 67, in get_model\r\n",
      "    dl_source)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/data.py\", line 144, in get_dataloader_factory\r\n",
      "    dl = DataLoaderDescription.load(yaml_path)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/components.py\", line 49, in load\r\n",
      "    return cls.from_config(parsed_dict)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/components.py\", line 31, in from_config\r\n",
      "    return related.to_model(cls, cfg)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/related/functions.py\", line 88, in to_model\r\n",
      "    value = cls(**value)\r\n",
      "  File \"<attrs generated init 172b9ed2e8d9cbcf7cb0e66e16a19af0e4c5db9f>\", line 7, in __init__\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/related/converters.py\", line 27, in __call__\r\n",
      "    return to_model(self.cls, value)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/related/functions.py\", line 88, in to_model\r\n",
      "    value = cls(**value)\r\n",
      "  File \"<attrs generated init 82933eeda5d27b5362a0dbbfbf4a305f29b3e561>\", line 5, in __init__\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/external/related/converters.py\", line 60, in __call__\r\n",
      "    kwargs[key_value] = self.__call__(item)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/kipoi/external/related/converters.py\", line 52, in __call__\r\n",
      "    return to_model(self.cls, value)\r\n",
      "  File \"/opt/modules/i12g/anaconda/3-4.1.1/lib/python3.5/site-packages/related/functions.py\", line 88, in to_model\r\n",
      "    value = cls(**value)\r\n",
      "TypeError: __init__() got an unexpected keyword argument 'shape'\r\n"
     ]
    }
   ],
   "source": [
    "!kipoi test ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the model through kipoi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kipoi' from '/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/kipoi/__init__.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(kipoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'output_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-025cc5fb6d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkipoi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# See also python-sdk.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/kipoi/model.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(model, source, with_dataloader)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdefault_dataloader_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         default_dataloader = kipoi.get_dataloader_factory(default_dataloader_path,\n\u001b[0;32m---> 67\u001b[0;31m                                                           dl_source)\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdefault_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/kipoi/data.py\u001b[0m in \u001b[0;36mget_dataloader_factory\u001b[0;34m(dataloader, source)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Setup dataloader description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoaderDescription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;31m# --------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# input the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/kipoi/components.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"path\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mparsed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/kipoi/components.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#     raise ValueError(\"The following arguments were not specified: {0}. Please specify them.\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#                      format(undefined_set))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrelated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-4.1.1/envs/dev-kipoi-py35/lib/python3.5/site-packages/related/functions.py\u001b[0m in \u001b[0;36mto_model\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'output_schema'"
     ]
    }
   ],
   "source": [
    "m = kipoi.get_model(\".\", source=\"dir\")  # See also python-sdk.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Congrats! You made it through the tutorial! Feel free to use this model for your model template."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev-kipoi-py35]",
   "language": "python",
   "name": "conda-env-dev-kipoi-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
